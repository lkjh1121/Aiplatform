비지도 학습은 결과를 알지 못할 때 하는 학습이다. (라벨이없다. target을 모를때)
지도학습 전에 무엇을 분석해야 할 지 모르거나, 특성이 너무 많아서
모든 특성을 처리하면 오히려 학습의 결과가 나쁠때(이미지), 
컬러이미지(3차원, 150, 150, 3) -> 1차원(67500, ) 특성의 숫자가 너무 많아서
오히려 학습이 저해가 된다. 차원 축소나 주요성분분석을 통해 중요한 성분만 빼내서 학습을 하면
오히려 성과가 더 좋을 수 있다. => 딥러닝 자체는 머신러닝과 동일하다

CNN(합성곱 신경망) - 자동으로 엄청나게 많은 수의 이미지 필터를 만들어낸다.
                    이 필터를 기반으로 학습을 진행하기 때문에 시간을 많이 잡아먹는다. 차원축소가 의미가 없어진다.
                    이미지 분석쪽에서 뛰어난 국가는 중국이다.

텍스트분석 : 원래는 머신러닝으로 진행하다가, 지금은 딥러닝의 RNN(순환신경망)을 활발하게 사용중이다.

특성 중에서 중요한 부분만 추출하거나 차원을 축소시키거나
비슷한 것끼리 묶고자 할 때 사용한다.

1. 데이터 전처리(정규화) - MinMaxScalar
    데이터들이 단위가 서로 다를때 어떤 알고리즘들은 이 단위가 학습에 영향을 미친다.
    비슷한 단위로 서로 묶고자 하는걸 정규화라 한다.
    선형회귀, 로지스틱회귀, 서포트벡터머신, 딥러닝 알고리리즘에는 정규화를 반드시 하자.

2. 차원축소, 주성분 분석( 암 환자 같은 경우 특성이 30개가 넘는데 산포도를 못그림)
    seaborn의 pair plot 특성이 많아야 10개 미만일때 그린다. 그래서 이런 경우에는
    주성분(알고리즘이 데이터들을 회전시켜서 중요한것만) 빼내서 시각화를 한다.

3. 군집, 연관성 분석등
    비지도 학습으로 끝이 아니라 지도학습을 하기 전에 데이터의 특성 파악에 주로 사용한다. 

지도학습   : fit - predict
비지도학습 : fit-transform (데이터 변형이 주가된다.)
            fit-transform 함수가 있다.


1. 데이터 전처리
    StandardScalar - 특성의 평균을 0으로 만들고 분산을 1로 만든다. 보편적으로 가장 많이 사용한다
    RoubutScalar - StandardScalar와 유사, 평균과 분산 대신에 중간값과 사분위값을 사용한다. 이상치 없음
    
    
    MinMaxScalar - 모든 특성이 0과 1사이에 위치하도록 한다
    Normalizer - 벡터의 유클리디언 길이가 1이 되도록 한다
    사용 방법이 동일

    딥러닝, 서포트 벡터머신, 로지스틱회귀분석 등에는 스케일링을 꼭 해야한다.